\documentclass[nojss]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation (and optionally ORCID link)
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Alexander Pate\\University of Manchester
  \And Glen P. Martin\\University of Manchester}
\Plainauthor{Alexander Pate, Glen P. Martin}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{calibmsm: An \proglang{R} package for calibration plots of a multistate model using inverse probability of censoring weights}
\Plaintitle{calibmsm: An R package for calibration plots of a multistate model using inverse probability of censoring weights}
\Shorttitle{calibmsm: An \proglang{R} package for calibration plots of a multistate model}

%% - \Abstract{} almost as usual
\Abstract{
  This vignette is a replica of the article published in \textbf{... ADD REF XXXX}.

  Multistate models, which allow users to answer a wide range of clinical questions, are becoming a more commonly used tool for clinical prediction. It is paramount to evaluate the calibration (as well as other metrics) of a risk prediction model before implementation of the model in practice. Currently no software exists to aid in assessing the calibration of a multistate model. \pkg{calibmsm} has been developed to simplify this process for practicing model developers. Calibration of the transition probabilities at time $t$, when in state $j$ at time $s$ are assessed. This is done using a combination of landmarking, calibration methods for binary logistic and multinomaial logistic regression models and inverse probability of censoring weights.

  This article details the methodology and provides a comprehensive example on how to assess the calibration of a model developed to predict recovery, adverse events, relapse and survival in patients with blood cancer after a transplantation. This model of interest is developed identically as in the comprehensive demonstration on how to develop a multistate model given by the developers of \pkg{mstate}.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Alexander Pate\\
  Division of Imaging, Informatics and Data Science\\
  Faculty of Biology, Medicine and Health\\
  University of Manchester
  M139PR, UK\\
  E-mail: \email{alexander.pate@manchester.ac.uk}\\
}

\begin{document}

---
vignette: >
  %\VignetteIndexEntry{overview}
  %\VignetteEncoding{UTF-8}
---

%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section[Introduction]{Introduction} \label{sec:intro}

% \begin{leftbar}
% The introduction is in principle ``as usual''. However, it should usually embed
% both the implemented \emph{methods} and the \emph{software} into the respective
% relevant literature. For the latter both competing and complementary software
% should be discussed (within the same software environment and beyond), bringing
% out relative (dis)advantages. All software mentioned should be properly
% \verb|\cite{}|d. (See also Appendix~\ref{app:bibtex} for more details on
% \textsc{Bib}{\TeX}.)
%
% For writing about software JSS requires authors to use the markup
% \verb|\proglang{}| (programming languages and large programmable systems),
% \verb|\pkg{}| (software packages), \verb|\code{}| (functions, commands,
% arguments, etc.). If there is such markup in (sub)section titles (as above), a
% plain text version has to be provided in the {\LaTeX} command as well. Below we
% also illustrate how abbrevations should be introduced and citation commands can
% be employed. See the {\LaTeX} code for more details.
% \end{leftbar}

Risk prediction models enable the prediction of clinical events in either diagnostic or prognostic settings \citep{VanSmeden2021} and are used widely to inform clinical practice. Multistate models are becoming more commonly developed in a risk prediction setting \citep{Putter2006, Le-Rademacher2018, Lintu2022, Masia2017}. Using a multistate model for prediction is important when the development of an intermediate condition occurring post index date may have an impact on the risk of future outcomes of interest. All risk prediction models developed for use in clinical practice should be validated in a relevant cohort prior to implementation \citep{Steyerberg2016, Sperrin2022}. A key part of the validation process is assessment of the calibration of the model \citep{VanCalster2019}. Ideally calibration curves should be produced which allow evaluation of the calibration over the entire distribution of predicted risk, corresponding to moderate assessment of calibration \citep{VanCalster2016}.

The \proglang{R} package \pkg{mstate} \citep{DeWreede2011} provides a comprehensive set of tools to develop a multistate model for a continuously observed multistate survival process. However, currently no software exists to aid researchers in assessing the calibration of a multistate model that has been developed. \pkg{calibmsm} has been developed to enable researchers to estimate calibration curves and scatter plots using the BLR-IPCW and MLR-IPCW approaches outlined by Pate et al \textbf{REF XXXX}, which focus on assessing the calibration of the transition probabilities out of the starting state. The work in this paper extends the framework to assess the calibration of transition probabilities out of any state $j$ at any time $s$ using landmarking \citep{Houwelingen2007, Dafni2011}, gives details on estimation of the weights, and demonstrates the process for estimating confidence intervals. \pkg{calibmsm} is available from the Comprehensive R Archive Network at \textbf{XXXX}.

\cite{DeWreede2011} used data from the European Society for Blood and Marrow Transplantation \citep{EBMT2023} to showcase how to develop, and the benefits of developing, a multistate model for clinical prediction. In this study, we show how to assess the calibration of a model developed on the same EBMT data. Details on the methodology are given in section 2. The clinical setting for our example and steps for data preparation and are described in section 3. In section 4, we show how to estimate calibration curves and scatter plots using \pkg{calibmsm}. In section 5 we demonstrate how to implement a bootstrapping procedure to estimate confidence intervals for the calibration curves.

%% Section 2: Methodology
\section{Methodology} \label{sec:methodology}

%Sub-section for setup
\subsection{Setup} \label{sec:setup}

Let $X(t) \in \{1, ..., K\}$ be a multistate survival process with $K$ states. We assume a multistate model has already been developed and we want to assess the calibration of the predicted transition probabilities, $\hat{p}_{j,k}(s, t)$, in a cohort of interest. The transition probabilities are the probability of being in state $k$ at time $t$, if in state $j$ at time $s$. The aim is to estimate observed event probabilities: $$o_{j,k}(s,t) = P[X(t)=k|X(s) = j, \hat{p}_{j,k}(s,t)].$$

These can be estimated by fitting an appropriate model in a landmark cohort of individuals in state $j$ at time $s$. We propose doing this using cross sectional calibration techniques in the group of landmarked individuals who are also uncensored at time $t$ (i.e. methods to assess the calibration of models predicting binary or polytomous outcomes). Unless censoring is non-informative and there are no absorbing states, calibration must be assessed in a cohort reweighted using inverse probability of censoring weights. Appropriate calibration models and the process for calculating the weights are detailed in sections \ref{sec:weights} - \ref{sec:mlripcw}.

%Sub-section for IPCW weights
\subsection{Estimation of the inverse probability of censoring weights} \label{sec:weights}

The estimand for the weights is $w_{j}(s,t)$, the inverse of the probability of being uncensored at time $t$ if in state $j$ at time $s$:

$$w_{j}(s,t) = \frac{1}{P[t_{cens} > t|t > s, X(s) = j, \textbf{Z},\textbf{X(t)}]},$$

where $\textbf{X(t)}$ denotes the history of the multistate survival process up to time $t$, including the transition times. First the estimator $\hat{P}[t_{cens} > t|t > s, X(s) = j, \textbf{Z}]$ is calculated by developing an appropriate survival model. The outcome in this model is the time until censoring occurs. Moving into an absorbing state acts as the censoring mechanism in this model. $\textbf{X(t)}$ is explicitly conditioned on when defining $w_{j}(s,t)$ because the weights must reflect that censoring can no longer be observed for an individual if they enter an absorbing state at some time $t_{abs} < t$. Therefore

$$\hat{P}[t_{cens} > t|t > s, X(s) = j, \textbf{Z},\textbf{X(t)}] = \hat{P}[t_{cens} > t_{abs}|t > s, X(s) = j, \textbf{Z}]$$

if $X(t)$ is in an absorbing state, and

$$\hat{P}[t_{cens} > t|t > s, X(s) = j, \textbf{Z},\textbf{X(t)}] = \hat{P}[t_{cens} > t|t > s, X(s) = j, \textbf{Z}]$$

otherwise. In \code{calibmsm}, $\hat{P}[t_{cens} > t|t > s, X(s) = j, \textbf{Z}]$ is estimated using a cox proportional hazards model where all predictors $\textbf{Z}$ are assumed to have a linear effect on the log-hazard. However users can also input their own vector of weights. Given the BLR-IPCW and MLR-IPCW approaches are both reliant on correct estimation of the weights, we encourage users to take the time to carefully estimate weights themselves using non-linear models of $\textbf{Z}$ and interaction terms when appropriate.

Stabilised weights can be estimated by multiplying by the weights $w_{j}(s, t)$ by the mean probability of being uncensored:

$$w_{j}^{stab}(s, t) = \frac{P[t_{cens} > t|t > s, X(s) = j]}{P[t_{cens} > t|t > s, X(s) = j, \textbf{Z},\textbf{X(t)}]}.$$

The numerator can be estimated using an intercept only model, and note there is no dependence on $\textbf{X(t)}$.

Another option is to estimate $w(s,t)$, which is the inverse of the probability of being uncensored at time $t$ if uncensored at time $s$:

$$w(s,t) = \frac{1}{P[t_{cens} > t|t > s, \textbf{Z},\textbf{X(t)}]}.$$

This can be estimated using the same approach as for $w_{j}(s,t)$, except there is no requirement to be in state $j$ when landmarking at time $s$. If the censoring mechanism is non-informative after conditioning on the predictors $\textbf{Z}$, then $w(s,t) = w_{j}(s,t)$, and any consistent estimator for $w(s,t)$ will be a consistent estimator of $w_{j}(s,t)$. The advantage is that $\hat{w}(s,t)$ is calculated by developing a model in the cohort of individuals uncensored at time $s$, which is a larger cohort than those uncensored and in state $j$ at time $s$. Therefore $\hat{w}(s,t)$ will be a more precise estimator than $\hat{w}_{j}(s,t)$. On the contrary, if the assumption of non-informative censoring after conditioning on $\textbf{Z}$, there is a risk of bias.

%Sub-section for BLR-IPCW calibration plots
\subsection{BLR-IPCW calibration curves} \label{sec:blripcw}

The first approach produces calibration curves using a framework for binary logistic regression models with inverse probability of censoring weights (BLR-IPCW). Let $I_{k}(t)$ be an indicator for whether an individual is in state $k$ at time $t$. $I_{k}(t)$ is then modeled using a flexible approach with $\hat{p}_{j, k}(s, t)$ as the sole predictor. This model is fit in the reweighted landmark cohort (in state $j$ at time $s$) of individuals uncensored at time $t$. We suggest using a loess smoother:

$$I_{k}(t) = loess(\hat{p}_{j, k}(s, t)),$$
or a logistic regression model with restricted cubic splines:

$$logit(I_{k}(t)) = rcs(logit(\hat{p}_{j, k}(s, t))).$$

Any flexible model for binary outcomes could be used, but these are the most common and are implemented in this package. Observed event probabilities $\hat{o}_{j,k}(s,t)$ are then estimated as fitted values from these models. The calibration curve is plotted using the set of points $\{\hat{p}_{j, k}(s, t), \hat{o}_{j,k}(s,t)\}$.

%Sub-section for MLR-IPCW calibration plots
\subsection{MLR-IPCW calibration plots} \label{sec:mlripcw}

The second approach produces calibration scatter plots using a framework for multinomial logistic regression models with inverse probability of censoring weights (MLR-IPCW). Let $I_{X}(t)$ be an polytomous indicator variable taking values $I_{X}(t) \in \{1, ..., K\}$ such that $I_{X}(t) = k$ if an individual is in state $k$ at time $t$. The nominal recalibration framework of \cite{VanHoorde2014, VanHoorde2015} is then applied in the reweighted landmark cohort of individuals uncensored at time $t$. First calculate the log-ratios of the predicted transition probabilities:

$$\hat{LP}_{k} = ln\left(\frac{\hat{p}_{j, k}(s, t)}{\hat{p}_{j, k_{ref}}(s, t)}\right),$$

Then fit the following multinomial logistic regression model:

$$ln\left(\frac{P[I_{X}(t) = k]}{P[I_{X}(t) = k_{ref}]}\right) = \alpha_{k} + \sum_{h=2}^{K} \beta_{k,h}*s_{k}(\hat{LP}_{h}),$$

where $k_{ref}$ is an arbitrary reference category which can be reached from state $j$, $k \neq k_{ref}$ takes values in the set of states that can be reached from state $j$, and where $s$ is a vector spline smoother \citep{Yee2015}. Observed event probabilities $\hat{o}_{j,k}(s,t)$ are then estimated as fitted values from this model. This results in a calibration scatter plot rather than a curve due to all states being modeled simultaneously, as opposed to a "one vs all" approach. The scatter occurs because the observed event probabilities for state $k$ vary depending on the predicted transition probabilities of the other states. This is a stronger \citep{VanCalster2016} form of calibration than that evaluated by BLR-IPCW, and will also result in observed event probabilities which sum to 1.

%% Section 3: Data preperation
\section{Clinical setting and data preperation} \label{sec:dataprep}

We utilise data from the European Society for Blood and Marrow Transplantation \citep{EBMT2023}, containing multistate survival data after a transplant for patients with blood cancer. The start of follow up is the day of the transplant and the initial state is alive and in remission. There are three intermediate events ($2$: recovery, $3$: adverse event, or $4$: recovery + adverse event), and two absorbing states ($5$: relapse and $6$: death). This data is available from the \pkg{mstate} package \citep{DeWreede2011}.

Two datasets are provided to enable assessment of a multistate model fitted to these data. The first is \code{ebmtcal}, which is the same as the \code{ebmt} dataset provided in \code{mstate}, with two extra variables derived: time until censoring (\code{dtcens}) and an indicator for whether censoring was observed (\code{dtcens.s = 1}) or an absorbing state was entered (\code{dtcens.s = 0}). This dataset contains baseline information on year of transplant (\code{year}), age at transplant (\code{age}), prophylaxis given (\code{proph}), and whether the donor was gender matched (\code{match}). The second dataset provided is \code{msebmtcal}, which is the \code{ebmt} dataset converted into \code{msdata} format using the process outlined in \cite{DeWreede2011}. It contains all transition times, an event indicator for each transition, as well as a \code{trans} attribute containing the transition matrix. The package \pkg{magrittr} is also loaded to enable the use of pipes.

<<data>>=
library("calibmsm")
library("magrittr")

data("ebmtcal")
head(ebmtcal)

data("msebmtcal")
head(msebmtcal)
@

In the work of \cite{DeWreede2011}, the focus is on predicting transition probabilities at times $s = 0$ and $s = 100$, and comparing prognosis for patients in different states $j$ and with different predictor variables. We therefore focus on assessing the calibration of the transition probabilities made at these times. We estimate transition probabilities for each individual by developing a model as demonstrated in \cite{DeWreede2011}. The predicted transitions probabilities from each state $j$ at times $s = 0$ and $s = 100$ are contained in stacked datasets \code{tps0} and \code{tps100} respectively. A leave-one-out approach was used when estimating these transition probabilities. This allows validation to be assessed in the same dataset that the model was developed and any assessment of model performance will be free from in-sample optimism.

<<data>>=
data("tps0")
head(tps0)

data("tps100")
head(tps100)
@

The data has been structured this way for the following reasons. The \code{ebmtcal} dataset has one row per individual and provides the basis for assessing calibration. The models to estimate the observed event probabilities are fit within this dataset. The predicted risks are provided separately because there are more than one predicted transition probabilities for each individual (states $j$ and times $s$). The \code{msebmtcal} dataset is required to identify which individuals are in state $j$ at time $s$ in order to apply the landmarking. The code for deriving all these datasets is provided in the supplementary material \textbf{TODO}.

%% Section 4: Calibration curves and scatter plots
\section[Assessing calibration using calibration curves and scatter plots]{Assessing calibration using calibration curves and scatter plots} \label{sec:calibplots}

The procedure for producing calibration plots requires the use of two functions. The first function, \code{calc_calib_blr} or \code{calc_calib_mlr}, calculates the data for the calibration plot. The second function, \code{plot.calib_blr} or \code{plot.calib_mlr}, produces the plot. This approach allows users the flexibility of producing their own plots.

%% Subsection for j = 1, s = 0
\subsection[Plots out of state j = 1 at time s = 0]{Plots out of state $j = 1$ at time $s = 0$} \label{sec:plotsj1s0}

We start by producing calibration curves for the predicted transition probabilities out of state $j = 1$ at time $s = 0$. Given all individuals start in state $1$, there is no need to consider the transition probabilities out of states $j \neq 1$. We start by assigning the time at which calibration is assessed to be 5 years (1826 days). We then estimate the observed event probabilities for the transition into each state using the function \code{calc_calib_blr}. The \code{data.mstate} argument requires an object of class \code{msdata}. The \code{data.raw} argument requires a \code{data.frame} with variables \code{dtcens} and \code{dtcens.s}, plus any baseline predictors $\textbf{Z}$ used to estimate the weights. The predicted transition probabilities from state $j = 1$ at time $s = 0$ are extracted from the object \code{tps0}. We choose to estimate the calibration curves using restricted cubic splines, and 3 knots are chosen given the reasonably small size of the dataset. Weights are estimated using the internal estimation procedure and the predictor variables \code{year}, \code{agecl}, \code{proph} and \code{match}. The \code{w.landmark.type} argument assigns whether weights are estimated using all individuals uncensored at time $s$, or only those uncensored and in state $j$ at time $s$, as discussed in section \ref{sec:weights}. The maximum weight (\code{w.max = 10}) and stabilisation of weights (\code{stabilised = FALSE}) are left as default.

<<data>>=
t.eval <- 1826

dat.calib.blr <-
  calc_calib_blr(data.mstate = msebmtcal,
                 data.raw = ebmtcal,
                 j=1,
                 s=0,
                 t.eval = t.eval,
                 tp.pred = tps0 %>%
                  dplyr::filter(j == 1) %>%
                  dplyr::select(any_of(paste("pstate", 1:6, sep = ""))),
                 curve.type = "rcs",
                 rcs.nk = 3,
                 w.covs = c("year", "agecl", "proph", "match"))
@

The first element of \code{dat.calib.blr} (named \code{plotdata}) contains 6 data frames for the calibration curves of the transition probabilities into each of the six states, $k \in \{1,2,3,4,5,6\}$. Each data frame contains three columns, \code{id}: the identifier of each individual; \code{pred}: the predicted transition probabilities; \code{obs}: the observed event probabilities. These data frames have less rows than \code{ebmtcal} because calibration can only be assessed in individuals uncensored at time \code{t.eval}. The second element (named \code{metadata}) is a metadata argument containing a vector of the possible transitions from state $j$ (all states cannot necessarily be reached from state $j$), the size of the confidence interval (currently \code{false}), and the type of calibration curve (\code{rcs} or \code{loess}).

<<data>>=
str(dat.calib.blr[["plotdata"]])

str(dat.calib.blr[["metadata"]])
@

Calibration curves can then be generated using the S3 generic \code{plot} function. The calibration curves (Figure \ref{fig:blrj1s0}) indicate the level of calibration is different for the transition probabilities into each of the different states. The calibration into states $4$ and $6$ looks quite good, although there is under prediction and over prediction among individuals with the lowest and highest predicted risks respectively. State $2$ has good calibration over the majority of the predicted risks but over predicts a lot for individuals with the highest predicted risks. Transition probabilities into state $1$ are over predicted for almost the entire range of predicted risks, whereas state $3$ is under predicted over the entire range of predicted risk. Most importantly the calibration of the transition probabilities into state $5$ (Relapse), a key clinical outcome in this clinical settings, is extremely poor.

\begin{figure}[t!]
\centering
<<echo=TRUE, fig=TRUE, height=5, width=7.5>>=
plot(dat.calib.blr, combine = TRUE, nrow = 2, ncol = 3)
@
\caption{\label{fig:blrj1s0} BLR-IPCW calibration curves out of state j =  1 at time s = 0.}
\end{figure}

Next we use the MLR-IPCW to evaluate calibration which produces a calibration scatter plot. The process is identical except the use of the function \code{calc_calib_mlr}. The MLR-IPCW calibration plots are contained in Figure \ref{fig:mlrj1s0}.

<<data>>=
dat.calib.mlr <-
  calc_calib_mlr(data.mstate = msebmtcal,
                 data.raw = ebmtcal,
                 j=1,
                 s=0,
                 t.eval = 1826,
                 tp.pred = tps0 %>%
                   dplyr::filter(j == 1) %>%
                   dplyr::select(any_of(paste("pstate", 1:6, sep = ""))),
                 w.covs = c("year", "agecl", "proph", "match"),
                 w.landmark.type = "all")
@

\begin{figure}
\centering
<<echo=TRUE, fig=TRUE, height=5, width=7.5>>=
plot(dat.calib.mlr, combine = TRUE)
@
\caption{\label{fig:mlrj1s0} MLR-IPCW calibration curves out of state j =  1 at time s = 0.}
\end{figure}

%% -- Optional special unnumbered sections -------------------------------------
\section*{TO DO}

\begin{enumerate}
  \item Check the rug plots are being implemented with transparency, and add a input parameter to change the transparency
  \item Check the MLR-IPCW plots are being implemented with transparency, and add a input parameter to change the transparency
  \item Add some proper warnings into the functions in the package for stuff I have listed somewhere
\end{enumerate}

\section*{Computational details}

\textbf{WILL UPDATE THIS SECTION ONCE PACKAGE HAS BEEN FINALISED AND UPLOADED TO CRAN}

The results in this paper were obtained using
\proglang{R}~\Sexpr{paste(R.Version()[c("major", "minor")], collapse = ".")} with the
\pkg{dplyr}~\Sexpr{packageVersion("dplyr")},
\pkg{tidyr}~\Sexpr{packageVersion("tidyr")},
\pkg{ggplot2}~\Sexpr{packageVersion("ggplot2")},
\pkg{ggpubr}~\Sexpr{packageVersion("ggpubr")},
\pkg{Hmisc}~\Sexpr{packageVersion("Hmisc")},
\pkg{rms}~\Sexpr{packageVersion("rms")},
\pkg{VGAM}~\Sexpr{packageVersion("VGAM")},
\pkg{boot}~\Sexpr{packageVersion("boot")},
\pkg{survival}~\Sexpr{packageVersion("survival")},
\pkg{stats}~\Sexpr{packageVersion("stats")},
\pkg{magrittr}~\Sexpr{packageVersion("magrittr")}. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.

\section*{Acknowledgments}

\bibliography{refs}

%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section[Comparison of calibration curves for transition probabilities generated using pseudo-values]{\texorpdfstring{Comparison of calibration curves for transition probabilities generated\\ using pseudo-values}{Comparison of calibration curves for transition probabilities generated using pseudo-values}} \label{app:pseudo}

\section[Comparison of BLR-IPCW calibration curves for competing risks sub-models with those generated using graphical calibration curves]{\texorpdfstring{Comparison of BLR-IPCW calibration curves for competing risks sub-models with those generated using graphical calibration curves}{Comparison of BLR-IPCW calibration curves for competing risks\\ sub-models with those generated using graphical calibration curves}} \label{app:gcc}

\end{appendix}

\end{document}
