---
title: "BLR-IPCW-manual-bootstrap"
output: rmarkdown::html_vignette
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{BLR-IPCW-manual-bootstrap}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Data preperation

This vignette showcases how to manually apply a bootstrap procedure to estimate a confidence interval for the BLR-IPCW calibration curves when using a custom function to estimate the inverse probability of censoring weights.  We use data from the European Society for Blood and Marrow Transplantation [@EBMT2023], which contains multistate survival data after a transplant for patients with blood cancer. The start of follow up is the day of the transplant and the initial state is alive and in remission. There are three intermediate events ($2$: recovery, $3$: adverse event, or $4$: recovery + adverse event), and two absorbing states ($5$: relapse and $6$: death). This data was originally made available from the `mstate` package [@DeWreede2011].

We start by reminding ourselves of the EBMT [@DeWreede2011; @EBMT2023] validation datasets `ebmtcal` and `msebmtcal`, and the predicted transition probabilities out of state `j = 1` made at time `s = 0` from the multistate model (`tps0`). We also set the time at which we want to evaluate the transition probabilities `t`. Please refer to the [Overview vignette](https://alexpate30.github.io/calibmsm/articles/overview_vignette.pdf) for a more detailed description of this data.

```{r}
set.seed(101)

library(calibmsm)

data("ebmtcal")
head(ebmtcal)

data("msebmtcal")
head(msebmtcal)

data("tps0")
head(tps0)

t <- 1826
```

# Confidence intervals for BLR-IPCW using internal bootstrapping procedure

We now remind ourselves of the procedure for generating a confidence interval, and estimate confidence intervals for the BLR-IPCW calibration curves using the internal bootstrapping procedure, as is done in the [Overview vignette](https://alexpate30.github.io/calibmsm/articles/overview_vignette.pdf).

1. Resample validation dataset with replacement
2. Landmark the dataset for assessment of calibration
3. Calculate inverse probability of censoring weights
4. Fit the preferred calibration model in the landmarked dataset (restricted cubic splines or loess smoother)
5. Generate observed event probabilities for a fixed vector of predicted transition probabilities (specifically the predicted transition probabilities from the non-bootstrapped landmark validation dataset)

The code to produce the calibration curves with confidence intervals is as follows:

```{r}
dat_calib_blr <-
  calib_msm(data_ms = msebmtcal,
           data_raw = ebmtcal,
           j=1,
           s=0,
           t = t,
           tp_pred = tps0 |>
             dplyr::filter(j == 1) |>
             dplyr::select(any_of(paste("pstate", 1:6, sep = ""))),
           calib_type = 'blr',
           curve_type = "rcs",
           rcs_nk = 3,
           w_covs = c("year", "agecl", "proph", "match"),
           CI = 95,
           CI_R_boot = 200)
```

```{r, fig.width = 7.5, fig.height = 5, fig.fullwidth = TRUE, fig.cap = "Figure 2: Calibration plots using BLR-IPCW, confidence interval estimated using manual bootstrap procedure"}
plot(dat_calib_blr, combine = TRUE)
```

# Confidence intervals for BLR-IPCW by inputting custom weights funciton into calibmsm

While the above approach is accessible, it may lead to a misspecified model for the weights given the user has no control over the choice of model (Cox model) or the functional form of the predictor variables $\textbf{Z}$, where all continuous variables are assumed to have linear effects on the hazard, and there are no interaction terms. Potential issues with using the internal process for estimating the weights is exemplified in the [Evaluation-of-estimation-of-IPCWs vignette](Evaluation-of-estimation-of-IPCWs.html). We therefore encourage users to explore their data and produce a more suitable model to estimate the weights. Please see the [Overview vignette](https://alexpate30.github.io/calibmsm/articles/overview_vignette.pdf) for a definition of the estimand of the weights and how to estimate them. 

Once a function for estimating the weights has been defined, the internal bootstrapping procedure can then be applied with this function to estimate the weights. This function must contain the parameters that are in the `calc_weights` function, even if you do not plan to use these parameters. These parameters are then specified through arguments with the `w.` prefix in `calib_msm`. The user specified function may also contain extra parameters not in `calc_weights`, and these are specified through the `...` argument in `calib_msm`. We showcase this by defining a new function `calc_weights_manual`. For this example, we define it to be the same as `calc_weights` function. In practice, we do not recommend this, as this option is to allow the user to specify their own function for estimating the weights. Given our choice of function to estimate the weights, the calibration curve is the same as that from Figure 1, and the confidence interval is a similar size.

```{r}
calc_weights_manual <- calibmsm::calc_weights

dat_calib_blr_w_function <-
  calib_msm(data_ms = msebmtcal,
           data_raw = ebmtcal,
           j=1,
           s=0,
           t = t,
           tp_pred = tps0 |>
             dplyr::filter(j == 1) |>
             dplyr::select(any_of(paste("pstate", 1:6, sep = ""))),
           calib_type = 'blr',
           curve_type = "rcs",
           rcs_nk = 3,
           w_function = calc_weights_manual,
           w_covs = c("year", "agecl", "proph", "match"),
           CI = 95,
           CI_R_boot = 200)
```

```{r, fig.width = 7.5, fig.height = 5, fig.fullwidth = TRUE, fig.cap = "Figure 2: Calibration plots using BLR-IPCW, confidence interval estimated using internal bootstrap procedure with custom specification of function to estimate the weights"}
plot(dat_calib_blr_w_function, combine = TRUE, nrow = 2, ncol = 3)
```

# Confidence intervals for BLR-IPCW by manually running bootstrapping procedure with custom function for estimating the weights

Finally, we showcase how to run the bootstrapping procedure manually. This allows users to parallelise their code to reduce computational time. This is done by using the package *boot* [@Canty2022] in conjunction with `calib_msm`.

We start by creating a permanent object with the predicted risks of each individual. When the validation cohort `ebmtcal` is resampled, the appropriate predicted transition probabilities must also be resampled from this object.

```{r}
tp_pred <- tps0 |>
  dplyr::filter(j == 1) |>
  dplyr::select(any_of(paste("pstate", 1:6, sep = "")))
```

Next define the predicted transition probabilities over which the observed event probabilities will be plotted, which must be the same for every bootstrapped calibration curve. These are the predicted transition probabilities of the individuals who are uncensored at time `t`, which are the predicted transition probabilities for the original calibration curves.

```{r}
## Extract ids for individuals uncensored at t
ids_uncens <- ebmtcal |>
  subset(dtcens > t | (dtcens < t & dtcens_s == 0)) |>
  dplyr::pull(id)
## Extract the predicted risks out of state 1 for these individuals
tp_pred_plot <- tps0 |>
  dplyr::filter(j == 1 & id %in% ids_uncens) |>
  dplyr::select(any_of(paste("pstate", 1:6, sep = "")))
```

The calibration curves (with no confidence interval) are now calculated. We utilise the `calc_weights` function from **calibmsm** to estimate the weights, which is the function used internally. However, in practice the point of this exercise is to create a better performing model to estimate the weights than the one from the internal procedure. The vector of weights should have an entry for every row the validation dataset. For individuals who will not be included in the landmark cohort, or who are censored prior to time $t$, these weights can take any value as they will not be included when the calibration model is fitted.

```{r}
weights_manual <-
  calc_weights(data_ms = msebmtcal,
               data_raw = ebmtcal,
               covs = c("year", "agecl", "proph", "match"),
               t = t,
               s = 0,
               landmark_type = "state",
               j = 1,
               max_weight = 10,
               stabilised = FALSE)$ipcw
str(weights_manual)
```

The observed event probabilities can then be estimated using `calib_msm` and a call to the `weights` argument.

```{r}
dat_calib_boot_manual <-
  calib_msm(data_ms = msebmtcal,
           data_raw = ebmtcal,
           j = 1,
           s = 0,
           t = t,
           tp_pred = tp_pred,
           calib_type = 'blr',
           curve_type = "rcs",
           rcs_nk = 3,
           weights = weights_manual)
```

It is now time to estimate the confidence interval for this curve. We define a function `calc_obs_boot` to generate a bootstrapped calibration curve which is compatible with the `boot` function from the *boot* [@Canty2022] package. Within each bootstrapped dataset, weights are calculated and then a calibration curve is estimated using `calib_msm`. The use of the argument `tp.pred.plot` is essential here, to ensure the bootstrapped observed event probabilities are generated for the same vectors of predicted transition probabilities. The function is also written to estimate a curve for the transition probabilities into a specific state $k$, as the output for `boot` must be a vector, rather than a matrix. This is done by utilising the `transitions.out` argument in `calib_msm`.

```{r}
calc_obs_boot <- function(data, indices, tp_pred, state_k){
  
  ## Bootstrap dataset and predicted transition probabilities
  data_boot <- data[indices,]
  tp_pred_boot <- tp_pred[indices, ]
  
  ## Calculate weights
  ## In practice - replace this function with your own
  weights_manual <-
    calc_weights(data_ms = msebmtcal[msebmtcal$id %in% data_boot$id, ],
                 data_raw = data_boot,
                 covs = c("year", "agecl", "proph", "match"),
                 t = t,
                 s = 0,
                 landmark_type = "state",
                 j = 1,
                 max_weight = 10,
                 stabilised = FALSE)$ipcw
  
  ## Estimate bootstrapped calibration curve
  curve_est <-
    calib_msm(data_ms = msebmtcal[msebmtcal$id %in% data_boot$id, ],
             data_raw = data_boot,
             j=1,
             s=0,
             t = t,
             tp_pred = tp_pred_boot,
             calib_type = 'blr',
             curve_type = "rcs",
             rcs_nk = 3,
             weights = weights_manual,
             tp_pred_plot = tp_pred_plot,
             transitions_out = state_k)
  
  ## Extract observed event probabilities
  curve_obs <-
    curve_est[["plotdata"]][[paste("state", state_k, sep = "")]]$obs
  
  return(curve_obs)
  
}
```

The size of the confidence interval, the states $k$ which individuals may transition into from state $j$, and a list to store the data for the plots are then defined:

```{r}
alpha <- (1-95/100)/2
valid_transitions <- which(colSums(tp_pred) != 0)
plot_data_list <- vector("list", length(valid_transitions))
```

The bootstrap procedure is now applied to the validation dataset `ebmtcal` for each state $k$ in `valid_transitions`, and the upper and lower confidence bands are stored in a `data.frame` along with the calibration curve calculated earlier.

```{r}
for (k in 1:length(valid_transitions)){
  
  ## Assign state k
  state_k <- valid_transitions[k]
  
  ## Run bootstrapping
  boot_obs <- boot::boot(ebmtcal,
                         calc_obs_boot,
                         R = 200,
                         tp_pred = tp_pred,
                         state_k = state_k)$t
  
  ## Extract confidence bands
  lower <- apply(boot_obs, 2, stats::quantile, probs = alpha, na.rm = TRUE)
  upper <- apply(boot_obs, 2, stats::quantile, probs = 1-alpha, na.rm = TRUE)
  
  ## Assign output
  plot_data_list[[k]] <- data.frame(
    "pred" = dat_calib_boot_manual[["plotdata"]][[k]]$pred,
    "obs" = dat_calib_boot_manual[["plotdata"]][[k]]$obs,
    "obs_lower" = lower,
    "obs_upper" = upper)
  
}
```

Finally, metadata is added and the appropriate `class` is defined so that the data is in the same format as the output from `calib_msm`, meaning it can be used with the S3 generic `plot`. Note that in this example `assessed.transitions` = `valid_transitions`, but this may not be the case if you only estimated calibration curves for a subset of the possible transitions.

```{r}
metadata <- list("valid_transitions"= valid_transitions,
                 "assessed_transitions" = valid_transitions,
                 "CI" = 95,
                 "curve_type" = "rcs")
dat_calib_blr_manual <- list("plotdata" = plot_data_list, "metadata" = metadata)
attr(dat_calib_blr_manual, "class") <- c("calib_blr", "calib_msm")
```

The calibration curves with manually estimated confidence intervals are plotted in Figure 3. This Figure is very similar to Figures 1 and 2. This is to be expected given we have used the same model to estimate the weights that is used in the internal procedure, and verifies that the manual procedure for calculating the confidence interval has been successful.

```{r, fig.width = 7.5, fig.height = 5, fig.fullwidth = TRUE, fig.cap = "Figure 3: Calibration plots using BLR-IPCW, confidence interval estimated using manual bootstrap procedure"}
plot(dat_calib_blr_manual)
```

Code from these examples can be re-utilised, all that is required is to specify a function to estimate the inverse probability of censoring weights.

