@article{Austin2016,
abstract = {Propensity score methods are used to reduce the effects of observed confounding when using observational data to estimate the effects of treatments or exposures. A popular method of using the propensity score is inverse probability of treatment weighting (IPTW). When using this method, a weight is calculated for each subject that is equal to the inverse of the probability of receiving the treatment that was actually received. These weights are then incorporated into the analyses to minimize the effects of observed confounding. Previous research has found that these methods result in unbiased estimation when estimating the effect of treatment on survival outcomes. However, conventional methods of variance estimation were shown to result in biased estimates of standard error. In this study, we conducted an extensive set of Monte Carlo simulations to examine different methods of variance estimation when using a weighted Cox proportional hazards model to estimate the effect of treatment. We considered three variance estimation methods: (i) a na{\"{i}}ve model-based variance estimator; (ii) a robust sandwich-type variance estimator; and (iii) a bootstrap variance estimator. We considered estimation of both the average treatment effect and the average treatment effect in the treated. We found that the use of a bootstrap estimator resulted in approximately correct estimates of standard errors and confidence intervals with the correct coverage rates. The other estimators resulted in biased estimates of standard errors and confidence intervals with incorrect coverage rates. Our simulations were informed by a case study examining the effect of statin prescribing on mortality. {\textcopyright} 2016 The Authors. Statistics in Medicine published by John Wiley & Sons Ltd.},
author = {Austin, Peter C.},
doi = {10.1002/sim.7084},
file = {:/nask.man.ac.uk/home$/Downloads/Austin2016.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Monte Carlo simulations,inverse probability of treatment weighting (IPTW),observational study,propensity score,survival analysis,variance estimation},
number = {30},
pages = {5642--5655},
pmid = {27549016},
title = {{Variance estimation when using inverse probability of treatment weighting (IPTW) with survival analysis}},
volume = {35},
year = {2016}
}
@article{Lintu2022,
abstract = {Background: Understanding the progression of kidney disease is of great interest among clinicians. The multi-state model is an adequate tool to model the effects of covariates that influence the onset, progression, and regression of kidney function. Objective: The goal of the present study is to propose a stochastic model for kidney disease progression and to demonstrate the application of the same. Methodology: We proposed a semi-parametric continuous time homogeneous multi-state Markov model for the kidney disease progression data obtained from a retrospective study of 225 patients prescribed with colistin (a re-emerging antibiotic) in a tertiary care hospital in coastal Karnataka. Different stages of kidney disease were defined based on the Kidney Disease Improving Global Outcome (KDIGO) score. The model consists of three transient states, and an absorbing state death. Covariate effects on the bidirectional transition rates were estimated using the multi-state model. Results: We used the data of 225 patients to see their kidney disease progression. All the patients were under colistin therapy. The median length of hospital stay was 21 days. A total of 83 (36.89%) patients died in the hospital. The prognostic factors such as gender, hypertension, sepsis, and surgery are significant factors affecting kidney disease in different stages. Conclusion: The findings of the study will be useful for public health policymakers to implement the policies and treatment plans to improve the survival of the patients. Moreover, modelling the disease progression helps in understanding the expected burden of the disease.},
author = {Lintu, M. K. and Shreyas, K. M. and Kamath, Asha},
doi = {10.1016/j.cegh.2021.100946},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Lintu2022.pdf:pdf},
issn = {22133984},
journal = {Clinical Epidemiology and Global Health},
keywords = {Disease progression,Intermediate events,Kidney disease,Multi-state model,Transition intensity},
number = {December 2021},
pages = {100946},
publisher = {Elsevier B.V.},
title = {{A multi-state model for kidney disease progression}},
url = {https://doi.org/10.1016/j.cegh.2021.100946},
volume = {13},
year = {2022}
}
@article{Boulesteix2013,
abstract = {In computational science literature including, e.g., bioinformatics, computational statistics or machine learning, most published articles are devoted to the development of "new methods", while comparison studies are generally appreciated by readers but surprisingly given poor consideration by many journals. This paper stresses the importance of neutral comparison studies for the objective evaluation of existing methods and the establishment of standards by drawing parallels with clinical research. The goal of the paper is twofold. Firstly, we present a survey of recent computational papers on supervised classification published in seven high-ranking computational science journals. The aim is to provide an up-to-date picture of current scientific practice with respect to the comparison of methods in both articles presenting new methods and articles focusing on the comparison study itself. Secondly, based on the results of our survey we critically discuss the necessity, impact and limitations of neutral comparison studies in computational sciences. We define three reasonable criteria a comparison study has to fulfill in order to be considered as neutral, and explicate general considerations on the individual components of a "tidy neutral comparison study". R codes for completely replicating our statistical analyses and figures are available from the companion website http://www.ibe.med.uni-muenchen.de/organisation/mitarbeiter/020_professuren/boulesteix/plea2013. {\textcopyright} 2013 Boulesteix et al.},
author = {Boulesteix, Anne Laure and Lauer, Sabine and Eugster, Manuel J.A.},
doi = {10.1371/journal.pone.0061562},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Boulesteix2013.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pmid = {23637855},
title = {{A Plea for Neutral Comparison Studies in Computational Sciences}},
volume = {8},
year = {2013}
}
@article{VanHoorde2014,
author = {{Van Hoorde}, Kirsten and Vergouwe, Yvonne and Timmerman, Dirk and {Van Huffel}, Sabine and Steyerberg, W and {Van Calster}, Ben},
doi = {10.1002/sim.6114},
journal = {Statistics in Medicine},
number = {15},
pages = {2585--2596},
title = {{Assessing calibration of multinomial risk prediction models}},
volume = {33},
year = {2014}
}
@article{VanHouwelingen2015,
abstract = {By far the most popular model to obtain survival predictions for individual patients is the Cox model. The Cox model does not make any assumptions on the underlying hazard, but it relies heavily on the proportional hazards assumption. The most common ways to circumvent this robustness problem are 1) to categorize patients based on their prognostic risk score and to base predictions on Kaplan-Meier curves for the risk categories, or 2) to include interactions with the covariates and suitable functions of time. Robust estimators of the t0-year survival probabilities can also be obtained from a “stopped Cox” regression model, in which all observations are administratively censored at t0. Other recent approaches to solve this robustness problem, originally proposed in the context of competing risks, are pseudo-values and direct binomial regression, based on unbiased estimating equations. In this paper stopped Cox regression is compared with these direct approaches. This is done by means of a simulation study to assess the biases of the different approaches and an analysis of breast cancer data to get some feeling for the performance in practice. The tentative conclusion is that stopped Cox and direct models agree well if the follow-up is not too long. There are larger differences for long-term follow-up data. There stopped Cox might be more efficient, but less robust.},
author = {van Houwelingen, Hans C. and Putter, Hein},
doi = {10.1007/s10985-014-9299-3},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Houwelingen, Putter - 2015 - Comparison of stopped Cox regression with direct methods such as pseudo-values and binomial regression.pdf:pdf},
issn = {15729249},
journal = {Lifetime Data Analysis},
keywords = {Direct binomial regression,Landmarking,Proportional hazards regression,Pseudo-observations,Stopped Cox regression},
number = {2},
pages = {180--196},
pmid = {25084763},
title = {{Comparison of stopped Cox regression with direct methods such as pseudo-values and binomial regression}},
volume = {21},
year = {2015}
}
@article{Dafni2011,
abstract = {This statistical primer presents the landmark analysis method, exploring its appropriate use and interpretation while recognizing its limitationsThis observational method is used for comparing time-to-event outcome between groups determined during study follow-upThe goal of the landmark method is to estimate in an unbiased way the time-to-event probabilities in each group conditional on the group membership of patients at a specific time point, the landmark timeThe need that led to its development, the impact of the method, and its pros and cons, along with available alternative approaches, are presentedSimulations explore its performance, using realistic parameters from arecent cardiovascular studyAs long as the limitations of the method are recognized and the interpretation of its results clearly reflect their "conditional" nature, landmark analysis, 25 years from its introduction, can still be of value. {\textcopyright} 2011 American Heart Association, Inc.},
author = {Dafni, Urania},
doi = {10.1161/CIRCOUTCOMES.110.957951},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Dafni2011.pdf:pdf},
issn = {19417713},
journal = {Circulation: Cardiovascular Quality and Outcomes},
keywords = {Clinical trials,Observational studies,Prognostic factors,Time-to-event outcome,Time-varying covariate},
number = {3},
pages = {363--371},
pmid = {21586725},
title = {{Landmark analysis at the 25-year landmark point}},
volume = {4},
year = {2011}
}
@article{DeWreede2011,
author = {de Wreede, Liesbeth C and Fiocco, Marta and Putter, Hein},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Wreede, Fiocco, Putter - 2011 - mstate An R Package for the Analysis of Competing Risks and Multi-State Models.pdf:pdf},
journal = {Journal of Statistical Software},
number = {7},
title = {{mstate: An R Package for the Analysis of Competing Risks and Multi-State Models}},
url = {https://cran.r-project.org/package=mstate},
volume = {38},
year = {2011}
}
@book{Yee2015,
author = {Yee, Thomas W.},
doi = {10.1007/978-1-4939-2818-7},
edition = {1},
isbn = {978-1-4939-4198-8},
publisher = {Springer New York, NY},
title = {{Vector Generalized Linear and Additive Models}},
url = {https://link.springer.com/book/10.1007/978-1-4939-2818-7},
year = {2015}
}
@article{Sperrin2022,
abstract = {Clinical prediction models must be appropriately validated before they can be used. While validation studies are sometimes carefully designed to match an intended population/setting of the model, it is common for validation studies to take place with arbitrary datasets, chosen for convenience rather than relevance. We call estimating how well a model performs within the intended population/setting “targeted validation”. Use of this term sharpens the focus on the intended use of a model, which may increase the applicability of developed models, avoid misleading conclusions, and reduce research waste. It also exposes that external validation may not be required when the intended population for the model matches the population used to develop the model; here, a robust internal validation may be sufficient, especially if the development dataset was large.},
author = {Sperrin, Matthew and Riley, Richard D. and Collins, Gary S. and Martin, Glen P.},
doi = {10.1186/s41512-022-00136-8},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Sperrin2022.pdf:pdf},
issn = {2397-7523},
journal = {Diagnostic and Prognostic Research},
keywords = {Clinical prediction model,Generalisability,Validation,clinical prediction model,generalisability,validation},
number = {1},
pages = {4--9},
publisher = {BioMed Central},
title = {{Targeted validation: validating clinical prediction models in their intended population and setting}},
url = {https://doi.org/10.1186/s41512-022-00136-8},
volume = {6},
year = {2022}
}
@article{VanHoorde2015,
abstract = {Calibration refers to the reliability of the predicted risks, i.e. whether the predicted risks correspond to observed probabilities. In medical applications this is important because treatment decisions often rely on the estimated risk of disease. The aim of this paper is to present generic tools to assess the calibration of multiclass risk models.We describe a calibration framework based on a vector spline multinomial logistic regression model. This framework can be used to generate calibration plots and calculate the estimated calibration index (ECI) to quantify lack of calibration. We illustrate these tools in relation to risk models used to characterize ovarian tumors. The outcome of the study is the surgical stage of the tumor when relevant and the final histological outcome, which is divided into five classes: benign, borderline malignant, stage I, stage II-IV, and secondary metastatic cancer. The 5909 patients included in the study are randomly split into equally large training and test sets. We developed and tested models using the following algorithms: logistic regression, support vector machines, k nearest neighbors, random forest, naive Bayes and nearest shrunken centroids.Multiclass calibration plots are interesting as an approach to visualizing the reliability of predicted risks. The ECI is a convenient tool for comparing models, but is less informative and interpretable than calibration plots. In our case study, logistic regression and random forest showed the highest degree of calibration, and the naive Bayes the lowest.},
author = {{Van Hoorde}, K. and {Van Huffel}, S. and Timmerman, D. and Bourne, T. and {Van Calster}, B.},
doi = {10.1016/j.jbi.2014.12.016},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Hoorde et al. - 2015 - A spline-based tool to assess and visualize the calibration of multiclass risk predictions.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Calibration,Logistic regression,Machine learning,Multiclass,Probability estimation,Risk models},
pages = {283--293},
pmid = {25579635},
publisher = {Elsevier Inc.},
title = {{A spline-based tool to assess and visualize the calibration of multiclass risk predictions}},
url = {http://dx.doi.org/10.1016/j.jbi.2014.12.016},
volume = {54},
year = {2015}
}
@misc{DeCock2023,
author = {{De Cock}, Bavo and Nieboer, Daan and {Van Calster}, Ben and Steyerberg, Ewout W. and Vergouwe, Yvonne},
doi = {10.32614/CRAN.package.CalibrationCurves},
title = {{The CalibrationCurves package: assessing the agreement between observed outcomes and predictions.}},
url = {https://cran.r-project.org/package=CalibrationCurves},
year = {2023}
}
@article{Putter2006,
abstract = {An important aim in clinical studies in oncology is to study how treatment and prognostic factors influence the course of disease of a patient. Typically in these trials, besides overall survival, also other endpoints such as locoregional recurrence or distant metastasis are of interest. Most commonly in these situations, Cox regression models are applied for each of these endpoints separately or to composite endpoints such as disease-free survival. These approaches however fail to give insight into what happens to a patient after a first event. We re-analyzed data of 2795 patients from a breast cancer trial (EORTC 10854) by applying a multi-state model, with local recurrence, distant metastasis, and both local recurrence and distant metastasis as transient states and death as absorbing state. We used an approach where the clock is reset on entry of a new state. The influence of prognostic factors on each of the transition rates is studied, as well as the influence of the time at which intermediate events occur. The estimated transition rates between the states in the model are used to obtain predictions for patients with a given history. Formulas are developed and illustrated for these prediction probabilities for the clock reset approach. {\textcopyright} 2006 WILEY-VCH Verlag GmbH & Co. KGaA,.},
author = {Putter, Hein and {Van Hage}, Jos Der and {De Bock}, Geertruida H. and Elgalta, Rachid and {Van De Velde}, Cornelis J.H.},
doi = {10.1002/bimj.200510218},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Putter2006.pdf:pdf},
issn = {03233847},
journal = {Biometrical Journal},
keywords = {Multi-state model,Prediction,Prognostic factors,Survival analysis},
number = {3},
pages = {366--380},
pmid = {16845902},
title = {{Estimation and prediction in a multi-state model for breast cancer}},
volume = {48},
year = {2006}
}
@article{Putter2007,
abstract = {Standard survival data measure the time span from some time origin until the occurrence of one type of event. If several types of events occur, a model describing progression to each of these competing risks is needed.Multi-state models generalize competing risksmodels by also describing transitions to intermediate events. Methods to analyze such models have been developed over the last two decades. Fortunately, most of the analyzes can be performed within the standard statistical packages, but may require some extra effort with respect to data preparation and programming. This tutorial aims to review statistical methods for the analysis of competing risks and multi-state models. Although some conceptual issues are covered, the emphasis is on practical issues like data preparation, estimation of the effect of covariates, and estimation of cumulative incidence functions and state and transition probabilities. Examples of analysis with standard software are shown. Copyright q 2006 John Wiley & Sons, Ltd.},
author = {Putter, H and Fiocco, M and Geskus, R. B.},
doi = {https://doi.org/10.1002/sim.2712},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Putter, Fiocco, Geskus - 2007 - Tutorial in biostatistics Competing risks and multi-state models.pdf:pdf},
isbn = {2007090091480},
journal = {Statistics in medicine},
keywords = {competing risks,multi-state model,prediction,prognostic factors,survival analysis},
number = {11},
pages = {2389--2430},
pmid = {19455509},
title = {{Tutorial in biostatistics: Competing risks and multi-state models}},
url = {https://doi.org/10.1002/sim.2712},
volume = {26},
year = {2007}
}
@article{Krol2015,
abstract = {Multi-state models provide a relevant tool for studying the observations of a continuoustime process at arbitrary times. Markov models are often considered even if semi-Markov are better adapted in various situations. Such models are still not frequently applied mainly due to lack of available software. We have developed the R package SemiMarkov to fit homogeneous semi-Markov models to longitudinal data. The package performs maximum likelihood estimation in a parametric framework where the distributions of the sojourn times can be chosen between exponential, Weibull or exponentiated Weibull. The package computes and displays the hazard rates of sojourn times and the hazard rates of the semi-Markov process. The effects of covariates can be studied with a Cox proportional hazards model for the sojourn times distributions. The number of covariates and the distribution of sojourn times can be specified for each possible transition providing a great exibility in a model's definition. This article presents parametric semi-Markov models and gives a detailed description of the package together with an application to asthma control.},
author = {Kr{\'{o}}l, Agnieszka and Saint-Pierre, Philippe},
doi = {10.18637/jss.v066.i06},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Krol2015.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Asthma,Exponentiated weibull distribution,Multi-state semi-markov models,Parametric estimation,R},
number = {6},
pages = {1--16},
title = {{Semimarkov: An R package for parametric estimation in multi-state semi-markov models}},
volume = {66},
year = {2015}
}
@article{VanSmeden2021,
abstract = {Clinical prediction models play an increasingly important role in contemporary clinical care, by informing healthcare professionals, patients and their relatives about outcome risks, with the aim to facilitate (shared) medical decision making and improve health outcomes. Diagnostic prediction models aim to calculate an individual's risk that a disease is already present, whilst prognostic prediction models aim to calculate the risk of particular heath states occurring in the future. This article serves as a primer for diagnostic and prognostic clinical prediction models, by discussing the basic terminology, some of the inherent challenges, and the need for validation of predictive performance and the evaluation of impact of these models in clinical care.},
author = {van Smeden, Maarten and Reitsma, Johannes B. and Riley, Richard D. and Collins, Gary S. and Moons, Karel GM},
doi = {10.1016/j.jclinepi.2021.01.009},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Smeden et al. - 2021 - Clinical prediction models diagnosis versus prognosis.pdf:pdf},
issn = {18785921},
journal = {Journal of Clinical Epidemiology},
keywords = {Diagnostic,Model impact,Model performance,Prediction models,Prognostic,Reporting guidelines,Validation},
pages = {142--145},
pmid = {33775387},
publisher = {Elsevier},
title = {{Clinical prediction models: diagnosis versus prognosis}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2021.01.009},
volume = {132},
year = {2021}
}
@article{Choudhury2020,
abstract = {This report describes an R package, called the Individualized Coherent Absolute Risk Estimator (iCARE) tool, that allows researchers to build and evaluate models for absolute risk and apply them to estimate an individual's risk of developing disease during a specified time interval based on a set of user defined input parameters. An attractive feature of the software is that it gives users flexibility to update models rapidly based on new knowledge on risk factors and tailor models to different populations by specifying three input arguments: a model for relative risk, an age-specific disease incidence rate and the distribution of risk factors for the population of interest. The tool can handle missing information on risk factors for individuals for whom risks are to be predicted using a coherent approach where all estimates are derived from a single model after appropriate model averaging. The software allows single nucleotide polymorphisms (SNPs) to be incorporated into the model using published odds ratios and allele frequencies. The validation component of the software implements the methods for evaluation of model calibration, discrimination and risk-stratification based on independent validation datasets. We provide an illustration of the utility of iCARE for building, validating and applying absolute risk models using breast cancer as an example.},
author = {Choudhury, Parichoy Pal and Maas, Paige and Wilcox, Amber and Wheeler, William and Brook, Mark and Check, David and Garcia-Closas, Montserrat and Chatterjee, Nilanjan},
doi = {10.1371/journal.pone.0228198},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Choudrow.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {2},
pages = {1--25},
pmid = {32023287},
title = {{ICARE: An R package to build, validate and apply absolute risk models}},
url = {http://dx.doi.org/10.1371/journal.pone.0228198},
volume = {15},
year = {2020}
}
@article{Aalen1978,
abstract = {A product limit estimator is suggested for the transition probabilities of a non-homogeneous Markov chain with finitely many states. The estimator is expressed as a product integral and its properties are studied by means of the theory of square integrable martingales.},
author = {Aalen, Odd. O. and Johansen, Soren},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aalen, Johansen - 1978 - An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {0,1,6,censored observations,du,i,limit estimator,markov chains,p,product,q,rl,s,t,transition probabilities,u},
number = {3},
pages = {141--150},
title = {{An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations}},
volume = {5},
year = {1978}
}
@article{Le-Rademacher2018,
abstract = {Background/aims: The goal of this article is to illustrate the utility of multi-state models in cancer clinical trials. Our specific aims are to describe multi-state models and how they differ from standard survival methods, to illustrate how multi-state models can facilitate deeper understanding of the treatment effect on multiple paths along the disease process that patients could experience in cancer clinical trials, to explain the differences between multi-state models and time-dependent Cox models, and to briefly describe available software to conduct such analyses. Methods: Data from 717 newly diagnosed acute myeloid leukemia patients who enrolled in the CALGB 10603 trial were used as an illustrative example. The current probability-in-state was estimated using the Aalen–Johansen estimator. The restricted mean time in state was calculated as the area under the probability-in-state curves. Cox-type regression was used to evaluate the effect of midostaurin on the various clinical paths. Simulation was conducted using a newly constructed shiny application. All analyses were performed using the R software. Results: Multi-state model analyses of CALGB 10603 suggested that the overall improvement in survival with midostaurin seen in the primary analysis possibly resulted from a higher complete remission rate in combination with a lower risk of relapse and of death after complete remission in patients treated with midostaurin. Simulation results, in a three-state illness-death without recovery model, demonstrate that multi-state models and time-dependent Cox models evaluate treatment effects from different frameworks. Conclusion: Multi-state models allow detailed evaluation of treatment effects in complex clinical trial settings where patients can experience multiple paths between study enrollment and the final outcome. Multi-state models can be used as a complementary tool to standard survival analyses to provide deeper insights to the effects of treatment in trial settings with complex disease process.},
author = {Le-Rademacher, Jennifer G. and Peterson, Ryan A. and Therneau, Terry M. and Sanford, Ben L. and Stone, Richard M. and Mandrekar, Sumithra J.},
doi = {10.1177/1740774518789098},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Le-Rademacher.pdf:pdf},
issn = {17407753},
journal = {Clinical Trials},
keywords = {Multi-state model,cancer,clinical trials,survival analysis,time-to-event data},
number = {5},
pages = {489--498},
pmid = {30035644},
title = {{Application of multi-state models in cancer clinical trials}},
volume = {15},
year = {2018}
}
@misc{HarrellJr2023,
author = {{Harrell Jr}, Frank E},
title = {{Hmisc: Harrell Miscellaneous}},
url = {https://hbiostat.org/R/Hmisc/},
year = {2023}
}
@article{Jackson2016,
abstract = {Flexsurv is an R package for fully-parametric modeling of survival data. Any parametric time-to-event distribution may be fitted if the user supplies a probability density or hazard function, and ideally also their cumulative versions. Standard survival distributions are built in, including the three and four-parameter generalized gamma and F distributions. Any parameter of any distribution can be modeled as a linear or log-linear function of covariates. The package also includes the spline model of Royston and Parmar (2002), in which both baseline survival and covariate effects can be arbitrarily flexible parametric functions of time. The main model-fitting function, flexsurvreg, uses the familiar syntax of survreg from the standard survival package (Therneau 2016). Censoring or left-truncation are specified in ‘Surv' objects. The models are fitted by maximizing the full log-likelihood, and estimates and confidence intervals for any function of the model parameters can be printed or plotted. flexsurv also provides functions for fitting and predicting from fully-parametric multi-state models, and connects with the mstate package (de Wreede, Fiocco, and Putter 2011). This article explains the methods and design principles of the package, giving several worked examples of its use.},
author = {Jackson, Christopher H.},
doi = {10.18637/jss.v070.i08},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Jackson2016.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Multi-state models,Multistate models,Survival},
number = {8},
title = {{Flexsurv: A platform for parametric survival modeling in R}},
volume = {70},
year = {2016}
}
@article{VanCalster2019,
abstract = {Background: The assessment of calibration performance of risk prediction models based on regression or more flexible machine learning algorithms receives little attention. Main text: Herein, we argue that this needs to change immediately because poorly calibrated algorithms can be misleading and potentially harmful for clinical decision-making. We summarize how to avoid poor calibration at algorithm development and how to assess calibration at algorithm validation, emphasizing balance between model complexity and the available sample size. At external validation, calibration curves require sufficiently large samples. Algorithm updating should be considered for appropriate support of clinical practice. Conclusion: Efforts are required to avoid poor calibration when developing prediction models, to evaluate calibration when validating models, and to update models when indicated. The ultimate aim is to optimize the utility of predictive analytics for shared decision-making and patient counseling.},
author = {{Van Calster}, Ben and McLernon, David J. and {Van Smeden}, Maarten and Wynants, Laure and Steyerberg, Ewout W. and Bossuyt, Patrick and Collins, Gary S. and MacAskill, Petra and Moons, Karel G.M. and Vickers, Andrew J.},
doi = {10.1186/s12916-019-1466-7},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/vanCalster2019.pdf:pdf},
issn = {17417015},
journal = {BMC Medicine},
keywords = {Calibration,Heterogeneity,Model performance,Overfitting,Predictive analytics,Risk prediction models},
number = {1},
pages = {1--7},
pmid = {31842878},
publisher = {BMC Medicine},
title = {{Calibration: The Achilles heel of predictive analytics}},
volume = {17},
year = {2019}
}
@misc{Wickham2016,
author = {Wickham, Hadley},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {https://ggplot2.tidyverse.org},
year = {2016}
}
@article{Houwelingen2007,
author = {van Houwelingen, Hans C.},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/vanHouwelingen2007.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {dependent covariates,landmark analysis,landmarking,pseudo-partial likelihood,survival analysis,tim,time-varying effects},
number = {1},
pages = {70--85},
title = {{Dynamic Prediction by Landmarking in Event History Analysis}},
volume = {34},
year = {2007}
}
@article{Bazarova2023,
abstract = {We present an R-package for predictive modelling, CARRoT (Cross-validation, Accuracy, Regression, Rule of Ten). CARRoT is a tool for initial exploratory analysis of the data, which performs exhaustive search for a regression model yielding the best predictive power with heuristic 'rules of thumb' and expert knowledge as regularization parameters. It uses multiple hold-outs in order to internally validate the model. The package allows to take into account multiple factors such as collinearity of the predictors, event per variable rules (EPVs) and R-squared statistics during the model selection. In addition, other constraints, such as forcing specific terms and restricting complexity of the predictive models can be used. The package allows taking pairwise and three-way interactions between variables into account as well. These candidate models are then ranked by predictive power, which is assessed via multiple hold-out procedures and can be parallelised in order to reduce the computational time. Models which exhibited the highest average predictive power over all hold-outs are returned. This is quantified as absolute and relative error in case of continuous outcomes, accuracy and AUROC values in case of categorical outcomes. In this paper we briefly present statistical framework of the package and discuss the complexity of the underlying algorithm. Moreover, using CARRoT and a number of datasets available in R we provide comparison of different model selection techniques: based on EPVs alone, on EPVs and R-squared statistics, on lasso regression, on including only statistically significant predictors and on stepwise forward selection technique.},
author = {Bazarova, Alina and Raseta, Marko},
doi = {10.1371/journal.pone.0292597},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Bazarova.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {10 October},
pages = {1--22},
pmid = {37824552},
title = {{CARRoT: R-package for predictive modelling by means of regression, adjusted for multiple regularisation methods}},
url = {http://dx.doi.org/10.1371/journal.pone.0292597},
volume = {18},
year = {2023}
}
@article{Austin2014,
abstract = {Predicting the probability of the occurrence of a binary outcome or condition is important in biomedical research. While assessing discrimination is an essential issue in developing and validating binary prediction models, less attention has been paid to methods for assessing model calibration. Calibration refers to the degree of agreement between observed and predicted probabilities and is often assessed by testing for lack-of-fit. The objective of our study was to examine the ability of graphical methods to assess the calibration of logistic regression models. We examined lack of internal calibration, which was related to misspecification of the logistic regression model, and external calibration, which was related to an overfit model or to shrinkage of the linear predictor. We conducted an extensive set of Monte Carlo simulations with a locally weighted least squares regression smoother (i.e., the loess algorithm) to examine the ability of graphical methods to assess model calibration. We found that loess-based methods were able to provide evidence of moderate departures from linearity and indicate omission of a moderately strong interaction. Misspecification of the link function was harder to detect. Visual patterns were clearer with higher sample sizes, higher incidence of the outcome, or higher discrimination. Loess-based methods were also able to identify the lack of calibration in external validation samples when an overfit regression model had been used. In conclusion, loess-based smoothing methods are adequate tools to graphically assess calibration and merit wider application. {\textcopyright} 2013 John Wiley & Sons, Ltd.},
author = {Austin, Peter C. and Steyerberg, Ewout W.},
doi = {10.1002/sim.5941},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Austin2014loess.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Calibration,Graphical methods,Logistic regression,Prediction,Prediction models},
number = {3},
pages = {517--535},
pmid = {24002997},
title = {{Graphical assessment of internal and external calibration of logistic regression models by using loess smoothers}},
volume = {33},
year = {2014}
}
@article{Putter2018,
abstract = {The topic non-parametric estimation of transition probabilities in non-Markov multi-state models has seen a remarkable surge of activity recently. Two recent papers have used the idea of subsampling in this context. The first paper, by de U{\~{n}}a {\'{A}}lvarez and Meira-Machado, uses a procedure based on (differences between) Kaplan–Meier estimators derived from a subset of the data consisting of all subjects observed to be in the given state at the given time. The second, by Titman, derived estimators of transition probabilities that are consistent in general non-Markov multi-state models. Here, we show that the same idea of subsampling, used in both these papers, combined with the Aalen–Johansen estimate of the state occupation probabilities derived from that subset, can also be used to obtain a relatively simple and intuitive procedure which we term landmark Aalen–Johansen. We show that the landmark Aalen–Johansen estimator yields a consistent estimator of the transition probabilities in general non-Markov multi-state models under the same conditions as needed for consistency of the Aalen–Johansen estimator of the state occupation probabilities. Simulation studies show that the landmark Aalen–Johansen estimator has good small sample properties and is slightly more efficient than the other estimators.},
author = {Putter, Hein and Spitoni, Cristian},
doi = {10.1177/0962280216674497},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Putter2016.pdf:pdf},
isbn = {0962280216},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Markov assumption,Multi-state model,transition probability},
number = {7},
pages = {2081--2092},
pmid = {29846146},
title = {{Non-parametric estimation of transition probabilities in non-Markov multi-state models: The landmark Aalen–Johansen estimator}},
volume = {27},
year = {2018}
}
@misc{Martin2024,
author = {Martin, Glen P and Jenkins, David and Sperrin, Matthew},
title = {{predRupdate: Prediction Model Validation and Updating}},
url = {https://github.com/GlenMartin31/predRupdate},
year = {2024}
}
@incollection{Hernan2020,
address = {Boca Raton},
author = {Hernan, MA and Robins, JM},
booktitle = {Causal Inference: What If},
chapter = {12.2},
publisher = {Chapman & Hall/CRC},
title = {{12.2 Estimating IP weights via modeling}},
year = {2020}
}
@article{Austin2020,
abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
author = {Austin, Peter C. and Harrell, Frank E. and van Klaveren, David},
doi = {10.1002/sim.8570},
file = {:P\:/Documents/JournalsandPapers/Austin2019.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {calibration,model validation,random forests,survival analysis,time-to-event model},
number = {21},
pages = {2714--2742},
pmid = {32548928},
title = {{Graphical calibration curves and the integrated calibration index (ICI) for survival models}},
volume = {39},
year = {2020}
}
@article{Steyerberg2016,
abstract = {Chronic alcohol use and abuse result in widespread changes to gene expression, some of which contribute to the development of alcohol use disorders (AUD). Gene expression is, in part, controlled by a group of regulatory systems often referred to as epigenetic factors, which includes, among other mechanisms, chemical marks made on the histone proteins around which genomic DNA is wound to form chromatin, and on nucleotides of the DNA itself. In particular, alcohol has been shown to perturb the epigenetic machinery, leading to changes in gene expression and cellular functions characteristic of AUD and, ultimately, to altered behavior. DNA modifications in particular are seeing increasing research in the context of alcohol use and abuse. To date, studies of DNA modifications in AUD have primarily looked at global methylation profiles in human brain and blood, gene-specific methylation profiles in animal models, methylation changes associated with prenatal ethanol exposure, and the potential therapeutic abilities of DNA methyltransferase inhibitors. Future studies may be aimed at identifying changes to more recently discovered DNA modifications, utilizing new methods to discriminate methylation profiles between cell types and clarifying how alcohol influences the methylomes of cell type populations and how this may affect downstream processes. These studies and more in-depth probing of DNA methylation will be key to determining whether DNA-level epigenetic regulation plays a causative role in AUD and can thus be targeted for treatment of the disorder. Keywords},
author = {Steyerberg, Ewout W and {Harrell Jr}, Frank E},
doi = {10.1016/j.jclinepi.2015.04.005},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Steyerberg2016.pdf:pdf},
journal = {Journal of Clinical Epidemiology},
keywords = {determination,endothelium,estrogen,estrogen receptors,protein crystallography,protein data bank,r -factor,resolution,restraints,structure,structure interpretation,structure quality,structure refinement,structure validation,vascular smooth muscle},
pages = {245--247},
title = {{Prediction models need appropriate internal, internal-external, and external validation}},
volume = {69},
year = {2016}
}
@article{Riley2019,
abstract = {When designing a study to develop a new prediction model with binary or time-to-event outcomes, researchers should ensure their sample size is adequate in terms of the number of participants (n) and outcome events (E) relative to the number of predictor parameters (p) considered for inclusion. We propose that the minimum values of n and E (and subsequently the minimum number of events per predictor parameter, EPP) should be calculated to meet the following three criteria: (i) small optimism in predictor effect estimates as defined by a global shrinkage factor of ≥0.9, (ii) small absolute difference of ≤ 0.05 in the model's apparent and adjusted Nagelkerke's R2 , and (iii) precise estimation of the overall risk in the population. Criteria (i) and (ii) aim to reduce overfitting conditional on a chosen p, and require prespecification of the model's anticipated Cox-Snell R2 , which we show can be obtained from previous studies. The values of n and E that meet all three criteria provides the minimum sample size required for model development. Upon application of our approach, a new diagnostic model for Chagas disease requires an EPP of at least 4.8 and a new prognostic model for recurrent venous thromboembolism requires an EPP of at least 23. This reinforces why rules of thumb (eg, 10 EPP) should be avoided. Researchers might additionally ensure the sample size gives precise estimates of key predictor effects; this is especially important when key categorical predictors have few events in some categories, as this may substantially increase the numbers required.},
author = {Riley, Richard D. and Snell, Kym I.E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G.M. and Collins, Gary S.},
doi = {10.1002/sim.7992},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Riley et al. - 2019 - Minimum sample size for developing a multivariable prediction model PART II - binary and time-to-event outcomes.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {binary and time-to-event outcomes,logistic and Cox regression,multivariable prediction model,pseudo R-squared,sample size,shrinkage},
number = {7},
pages = {1276--1296},
title = {{Minimum sample size for developing a multivariable prediction model: PART II - binary and time-to-event outcomes}},
volume = {38},
year = {2019}
}
@misc{Canty2022,
author = {Canty, Angelo and Ripley, Brian},
title = {{boot: Bootstrap R (S-Plus) Functions}},
url = {https://cran.r-project.org/package=boot},
year = {2022}
}
@article{Pullenayegum2016,
abstract = {Background:The use of standard statistical methods in the medical literature has been studied extensively; however, the adoption of new methods has received less attention. We sought to understand (i) whether there is a perception that new methods are underused, (ii) what the barriers to use of new methods are, (iii) what dissemination activities are used, and (iv) user preferences for learning about new methods. Methods:We conducted a cross-sectional survey of members of the Statistical Society of Canada (SSC) and of principal investigators (knowledge-users) funded by the Canadian Institutes of Health Research (CIHR). Results: There were 157 CIHR respondents (14% response rate), and 39 respondents were statisticians from the Statistical Society of Canada. Seventy percent of CIHR respondents and 82% of statisticians felt that new developments were under-used. Barriers to use of new methods included lack of access to the necessary expertise (selected by over 90% of respondents), lack of suitable software (selected by 81% of statisticians), and lack of time to implement new methods (selected by 78% of statisticians). Greater access to statistical colleagues with an interest in collaboration and availability of software to implement new methods were the top-rated preferences among knowledge-users. Conclusions: There was a clear perception among all respondents that new statistical methods are underused. Encouraging statistical methodologists to develop a knowledge translation plan for improved dissemination and uptake, placing greater value on the role of the statistical collaborator in research, and providing software alongside new methods may improve the use of newly developed statistical methods.},
author = {Pullenayegum, Eleanor M. and Platt, Robert W. and Barwick, Melanie and Feldman, Brian M. and Offringa, Martin and Thabane, Lehana},
doi = {10.1002/sim.6633},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Pullenayegum2015.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Biostatistics,Collaboration,Knowledge,Translation},
number = {6},
pages = {805--818},
pmid = {26307183},
title = {{Knowledge translation in biostatistics: A survey of current practices, preferences, and barriers to the dissemination and uptake of new statistical methods}},
volume = {35},
year = {2016}
}
@book{Harrell2015,
address = {Cham},
author = {Harrell, Frank E},
edition = {Springer S},
publisher = {Springer},
title = {{Regression Modeling Strategies}},
year = {2015}
}
@misc{Pate,
author = {Pate, Alexander and Martin, Glen P.},
title = {calibmsm},
url = {https://alexpate30.github.io/calibmsm/},
year = {2024}
}
@article{Austin2022,
abstract = {Assessing calibration—the agreement between estimated risk and observed proportions—is an important component of deriving and validating clinical prediction models. Methods for assessing the calibration of prognostic models for use with competing risk data have received little attention.},
author = {Austin, Peter C. and Putter, Hein and Giardiello, Daniele and van Klaveren, David},
doi = {10.1186/s41512-021-00114-6},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Austin2022.pdf:pdf},
isbn = {4151202100114},
journal = {Diagnostic and Prognostic Research},
keywords = {Calibration,Competing risks,Survival analysis,Time,calibration,competing risks,model validation,random forests,survival analysis,time-to-event model},
number = {1},
publisher = {Diagnostic and Prognostic Research},
title = {{Graphical calibration curves and the integrated calibration index (ICI) for competing risk models}},
volume = {6},
year = {2022}
}
@article{Andersen2010,
abstract = {We review recent work on the application of pseudo-observations in survival and event history analysis. This includes regression models for parameters like the survival function in a single point, the restricted mean survival time and transition or state occupation probabilities in multi-state models, e.g. the competing risks cumulative incidence function. Graphical and numerical methods for assessing goodness-of-fit for hazard regression models and for the Fineĝ€"Gray model in competing risks studies based on pseudo-observations are also reviewed. Sensitivity to covariate-dependent censoring is studied. The methods are illustrated using a data set from bone marrow transplantation.},
author = {Andersen, Per Kragh and {Pohar Perme}, Maja},
doi = {10.1177/0962280209105020},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Andersen2010.pdf:pdf},
issn = {09622802},
journal = {Statistical Methods in Medical Research},
number = {1},
pages = {71--99},
pmid = {19654170},
title = {{Pseudo-observations in survival analysis}},
volume = {19},
year = {2010}
}
@article{Bull2020,
abstract = {Clinical prediction models (CPMs) predict the risk of health outcomes for individual patients. The majority of existing CPMs only harness cross-sectional patient information. Incorporating repeated measurements, such as those stored in electronic health records, into CPMs may provide an opportunity to enhance their performance. However, the number and complexity of methodological approaches available could make it difficult for researchers to explore this opportunity. Our objective was to review the literature and summarise existing approaches for harnessing repeated measurements of predictor variables in CPMs, primarily to make this field more accessible for applied researchers. MEDLINE, Embase and Web of Science were searched for articles reporting the development of a multivariable CPM for individual-level prediction of future binary or time-to-event outcomes and modelling repeated measurements of at least one predictor. Information was extracted on the following: the methodology used, its specific aim, reported advantages and limitations, and software available to apply the method. The search revealed 217 relevant articles. Seven methodological frameworks were identified: time-dependent covariate modelling, generalised estimating equations, landmark analysis, two-stage modelling, joint-modelling, trajectory classification and machine learning. Each of these frameworks satisfies at least one of three aims: to better represent the predictor-outcome relationship over time, to infer a covariate value at a pre-specified time and to account for the effect of covariate change. The applicability of identified methods depends on the motivation for including longitudinal information and the method's compatibility with the clinical context and available patient data, for both model development and risk estimation in practice.},
author = {Bull, Lucy M. and Lunt, Mark and Martin, Glen P. and Hyrich, Kimme and Sergeant, Jamie C.},
doi = {10.1186/s41512-020-00078-z},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Bull2020.pdf:pdf},
journal = {Diagnostic and Prognostic Research},
keywords = {Longitudinal data,Clinical risk prediction,Dynamic,ac,bull,clinical risk prediction,correspondence,dynamic prediction,electronic health records,joint models,longitudinal data,lucy,manchester,observations,personalised medicine,prediction models,repeated,survival analysis,time-dependent covariates,uk},
number = {1},
publisher = {Diagnostic and Prognostic Research},
title = {{Harnessing repeated measurements of predictor variables for clinical risk prediction: a review of existing methods}},
volume = {4},
year = {2020}
}
@book{Kleinbaum2012,
author = {Kleinbaum, David G. and Klein, Mitchel},
booktitle = {Evidence-Based Otolaryngology},
doi = {10.1007/978-1-4419-6646-9},
edition = {3rd},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/kleinbaum2012.pdf:pdf},
isbn = {978-1-4419-6645-2},
publisher = {Springer},
title = {{Survival Analysis: A Self-Learning Text}},
year = {2012}
}
@article{Grand2018,
author = {Grand, Mia K and de Witte, Theo J M and Putter, Hein},
doi = {10.1002/bimj.201700194},
journal = {Biometrical Journal},
number = {4},
pages = {737--747},
title = {{Dynamic prediction of cumulative incidence functions by direct binomial regression}},
volume = {60},
year = {2018}
}
@misc{RCoreTeam2023,
abstract = {R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/.},
address = {Vienna},
author = {{R Core Team}},
booktitle = {R Foundation for Statistical Computing},
editor = {Team, R Development Core},
publisher = {R Foundation for Statistical Computing},
series = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {https://www.r-project.org/},
year = {2023}
}
@article{Gerds2014,
abstract = {A predicted risk of 17% can be called reliable if it can be expected that the event will occur to about 17 of 100 patients who all received a predicted risk of 17%. Statistical models can predict the absolute risk of an event such as cardiovascular death in the presence of competing risks such as death due to other causes. For personalized medicine and patient counseling, it is necessary to check that the model is calibrated in the sense that it provides reliable predictions for all subjects. There are three often encountered practical problems when the aim is to display or test if a risk prediction model is well calibrated. The first is lack of independent validation data, the second is right censoring, and the third is that when the risk scale is continuous, the estimation problem is as difficult as density estimation. To deal with these problems, we propose to estimate calibration curves for competing risks models based on jackknife pseudo-values that are combined with a nearest neighborhood smoother and a cross-validation approach to deal with all three problems. {\textcopyright} 2014 John Wiley & Sons, Ltd.},
author = {Gerds, Thomas A. and Andersen, Per K. and Kattan, Michael W.},
doi = {10.1002/sim.6152},
file = {:P\:/Documents/JournalsandPapers/Gerds2014.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Calibration plots,Competing risks,Kernel smoothing,Pseudo-values,Risk models},
number = {18},
pages = {3191--3203},
pmid = {24668611},
title = {{Calibration plots for risk prediction models in the presence of competing risks}},
volume = {33},
year = {2014}
}
@article{VanCalster2016,
abstract = {Objective Calibrated risk models are vital for valid decision support. We define four levels of calibration and describe implications for model development and external validation of predictions. Study Design and Setting We present results based on simulated data sets. Results A common definition of calibration is "having an event rate of R% among patients with a predicted risk of R%," which we refer to as "moderate calibration." Weaker forms of calibration only require the average predicted risk (mean calibration) or the average prediction effects (weak calibration) to be correct. "Strong calibration" requires that the event rate equals the predicted risk for every covariate pattern. This implies that the model is fully correct for the validation setting. We argue that this is unrealistic: the model type may be incorrect, the linear predictor is only asymptotically unbiased, and all nonlinear and interaction effects should be correctly modeled. In addition, we prove that moderate calibration guarantees nonharmful decision making. Finally, results indicate that a flexible assessment of calibration in small validation data sets is problematic. Conclusion Strong calibration is desirable for individualized decision support but unrealistic and counter productive by stimulating the development of overly complex models. Model development and external validation should focus on moderate calibration.},
author = {{Van Calster}, Ben and Nieboer, Daan and Vergouwe, Yvonne and {De Cock}, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
doi = {10.1016/j.jclinepi.2015.12.005},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Calster et al. - 2016 - A calibration hierarchy for risk models was defined From utopia to empirical data.pdf:pdf},
issn = {18785921},
journal = {Journal of Clinical Epidemiology},
keywords = {Calibration,Decision curve analysis,External validation,Loess,Overfitting,Risk prediction models},
pages = {167--176},
pmid = {26772608},
publisher = {Elsevier Inc},
title = {{A calibration hierarchy for risk models was defined: From utopia to empirical data}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2015.12.005},
volume = {74},
year = {2016}
}
@article{Masia2017,
author = {Masia, Mar and Padilla, Sergio and Moreno, Santiago and Barber, Xavier and Iribarren, Jose A and Romero, Jorge and LIST, NEED TO FINISH AUTHOR},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Masia2017.pdf:pdf},
isbn = {1111111111},
journal = {PLoS ONE},
pages = {1--16},
title = {{Prediction of long-term outcomes of HIV- infected patients developing non-AIDS events using a multistate approach}},
volume = {112},
year = {2017}
}
@article{Pate2024,
abstract = {Introduction. There is currently no guidance on how to assess the calibration of multistate models used for risk prediction. We introduce several techniques that can be used to produce calibration plots for the transition probabilities of a multistate model, before assessing their performance in the presence of non-informative and informative censoring through a simulation. Methods. We studied pseudo-values based on the Aalen-Johansen estimator, binary logistic regression with inverse probability of censoring weights (BLR-IPCW), and multinomial logistic regression with inverse probability of censoring weights (MLR-IPCW). The MLR-IPCW approach results in a calibration scatter plot, providing extra insight about the calibration. We simulated data with varying levels of censoring and evaluated the ability of each method to estimate the calibration curve for a set of predicted transition probabilities. We also developed evaluated the calibration of a model predicting the incidence of cardiovascular disease, type 2 diabetes and chronic kidney disease among a cohort of patients derived from linked primary and secondary healthcare records. Results. The pseudo-value, BLR-IPCW and MLR-IPCW approaches give unbiased estimates of the calibration curves under non-informative censoring. These methods remained unbiased in the presence of informative censoring, unless the mechanism was strongly informative, with bias concentrated in the areas of predicted transition probabilities of low density. Conclusions. We recommend implementing either the pseudo-value or BLR-IPCW approaches to produce a calibration curve, combined with the MLR-IPCW approach to produce a calibration scatter plot, which provides additional information over either of the other methods.},
archivePrefix = {arXiv},
arxivId = {2308.13394},
author = {Pate, Alexander and Sperrin, Matthew and Riley, Richard D. and Peek, Niels and {Van Staa}, Tjeerd and Sergeant, Jamie C. and Mamas, Mamas A. and Lip, Gregory Y. H. and Flaherty, Martin O and Barrowman, Michael and Buchan, Iain and Martin, Glen P.},
doi = {10.1002/sim.10094},
eprint = {2308.13394},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Pate2024.pdf:pdf},
journal = {Statistics in Medicine},
keywords = {calibration,clinical prediction,model validation,multistate model,risk prediction},
number = {April},
pages = {1--23},
title = {{Calibration plots for multistate risk predictions models}},
url = {https://pubmed.ncbi.nlm.nih.gov/38720592/},
year = {2024}
}
@article{Carstensen2011,
abstract = {The Lexis class in the R package Epi provides tools for creation, manipulation and display of data from multi-state models. Transitions between states are described by rates (intensities); Lexis objects represent this kind of data and provide tools to show states and transitions annotated by relevant summary numbers. Data can be transformed to a form that allows modelling of several transition rates with common parameters.},
author = {Carstensen, Bendix and Plummer, Martyn},
doi = {10.18637/jss.v038.i06},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Carstensen2011.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Epidemiology,Multi-state models,R,Survival analysis},
number = {6},
pages = {1--18},
title = {{Using Lexis objects for multi-state models in R}},
volume = {38},
year = {2011}
}
@article{Crowson2016,
abstract = {Current methods used to assess calibration are limited, particularly in the assessment of prognostic models. Methods for testing and visualizing calibration (e.g. the Hosmer-Lemeshow test and calibration slope) have been well thought out in the binary regression setting. However, extension of these methods to Cox models is less well known and could be improved. We describe a model-based framework for the assessment of calibration in the binary setting that provides natural extensions to the survival data setting. We show that Poisson regression models can be used to easily assess calibration in prognostic models. In addition, we show that a calibration test suggested for use in survival data has poor performance. Finally, we apply these methods to the problem of external validation of a risk score developed for the general population when assessed in a special patient population (i.e. patients with particular comorbidities, such as rheumatoid arthritis).},
author = {Crowson, Cynthia S. and Atkinson, Elizabeth J. and Therneau, Terry M. and Lawson, Andrew B. and Lee, Duncan and MacNab, Ying},
doi = {10.1177/0962280213497434},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Crowson2013.pdf:pdf},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Cox model,Poisson,calibration,prognostic risk scores,standardized incidence ratio,survival},
number = {4},
pages = {1692--1706},
pmid = {23907781},
title = {{Assessing calibration of prognostic risk scores}},
volume = {25},
year = {2016}
}
@article{Jackson2011,
abstract = {The Journal of Statistical Software is an e-journal that publishes and reviews open source statistical software. We discuss the history, motivation, and implementation of the journal. {\textcopyright} 2009 John Wiley & Sons, Inc.},
author = {Jackson, Christopher H},
doi = {10.1002/wics.10},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jackson - 2011 - Multi-State Models for Panel Data The msm Package for R.pdf:pdf},
issn = {19395108},
journal = {Journal of Statistical Software},
keywords = {1,markov models,markov multi-state models for,msm,multi-state models,panel data,r},
number = {8},
pages = {128--129},
title = {{Multi-State Models for Panel Data: The msm Package for R}},
url = {https://cran.r-project.org/package=msm},
volume = {38},
year = {2011}
}
@misc{EBMT2023,
author = {EBMT},
title = {{Data from the European Society for Blood and Marrow Transplantation}},
url = {https://search.r-project.org/CRAN/refmans/mstate/html/EBMT-data.html},
year = {2023}
}
@book{Grolemund2023,
author = {Grolemund, G and Cetinkaya-Rundel, M and Wickham, H},
edition = {2},
isbn = {1492097403},
publisher = {O'Reilly Media},
title = {{R for Data Science}},
url = {https://r4ds.hadley.nz/},
year = {2023}
}
@article{Andersen2022,
abstract = {Multi-state models are frequently used when data come from subjects observed over time and where focus is on the occurrence of events that the subjects may experience. A convenient modeling assumption is that the multi-state stochastic process is Markovian, in which case a number of methods are available when doing inference for both transition intensities and transition probabilities. The Markov assumption, however, is quite strict and may not fit actual data in a satisfactory way. Therefore, inference methods for non-Markov models are needed. In this paper, we review methods for estimating transition probabilities in such models and suggest ways of doing regression analysis based on pseudo observations. In particular, we will compare methods using land-marking with methods using plug-in. The methods are illustrated using simulations and practical examples from medical research.},
author = {Andersen, Per Kragh and Wandall, Eva Nina Sparre and {Pohar Perme}, Maja},
doi = {10.1007/s10985-022-09560-w},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Andersen2022.pdf:pdf},
issn = {15729249},
journal = {Lifetime Data Analysis},
keywords = {Land-marking,Markov process,Multi-state model,Non-Markov model,Plug-in,Pseudo observations,State occupation probability,Survival analysis,Transition intensity,Transition probability},
number = {4},
pages = {585--604},
publisher = {Springer US},
title = {{Inference for transition probabilities in non-Markov multi-state models}},
url = {https://doi.org/10.1007/s10985-022-09560-w},
volume = {28},
year = {2022}
}
@article{Heinze2022,
abstract = {Although the biostatistical scientific literature publishes new methods at a very high rate, many of these developments are not trustworthy enough to be adopted by the scientific community. We propose a framework to think about how a piece of methodological work contributes to the evidence base for a method. Similarly to the well-known phases of clinical research in drug development, we define four phases of methodological research. These four phases cover (I) providing logical reasoning and proofs, (II) providing empirical evidence, first in a narrow target setting, then (III) in an extended range of settings and for various outcomes, accompanied by appropriate application examples, and (IV) investigations that establish a method as sufficiently well-understood to know when it is preferred over others and when it is not. We provide basic definitions of the four phases but acknowledge that more work is needed to facilitate unambiguous classification of studies into phases. Methodological developments that have undergone all four proposed phases are still rare, but we give two examples with references. Our concept rebalances the emphasis to studies in phase III and IV, i.e., carefully planned methods comparison studies and studies that explore the empirical properties of existing methods in a wider range of problems.},
author = {Heinze, Georg and Boulesteix, Anne-Laure and Kammer, Michael and Morris, Tim P. and White, Ian R.},
doi = {10.1002/bimj.202200222},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Heinze2023.pdf:pdf},
journal = {Biometrical Journal},
keywords = {2 institute for medical,biometry and epidemiology,information,ludwig-maximilians university of,processing},
number = {1},
pages = {e2200222},
pmid = {36737675},
title = {{Phases of methodological research in biostatistics - building the evidence base for new methods}},
volume = {66},
year = {2024}
}
@article{Austin2021,
abstract = {The Fine-Gray subdistribution hazard model has become the default method to estimate the incidence of outcomes over time in the presence of competing risks. This model is attractive because it directly relates covariates to the cumulative incidence function (CIF) of the event of interest. An alternative is to combine the different cause-specific hazard functions to obtain the different CIFs. A limitation of the subdistribution hazard approach is that the sum of the cause-specific CIFs can exceed 1 (100%) for some covariate patterns. Using data on 9479 patients hospitalized with acute myocardial infarction, we estimated the cumulative incidence of both cardiovascular death and non-cardiovascular death for each patient. We found that when using subdistribution hazard models, approximately 5% of subjects had an estimated risk of 5-year all-cause death (obtained by combining the two cause-specific CIFs obtained from subdistribution hazard models) that exceeded 1. This phenomenon was avoided by using the two cause-specific hazard models. We provide a proof that the sum of predictions exceeds 1 is a fundamental problem with the Fine-Gray subdistribution hazard model. We further explored this issue using simulations based on two different types of data-generating process, one based on subdistribution hazard models and other based on cause-specific hazard models. We conclude that care should be taken when using the Fine-Gray subdistribution hazard model in situations with wide risk distributions or a high cumulative incidence, and if one is interested in the risk of failure from each of the different event types.},
author = {Austin, Peter C. and Steyerberg, Ewout W. and Putter, Hein},
doi = {10.1002/sim.9023},
file = {:P\:/Documents/JournalsandPapers/Austin2021.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {cause-specific hazard function,competing risks,cumulative incidence function,subdistribution hazard,survival analysis},
number = {19},
pages = {4200--4212},
pmid = {33969508},
title = {{Fine-Gray subdistribution hazard models to simultaneously estimate the absolute risk of different event types: Cumulative total failure probability may exceed 1}},
volume = {40},
year = {2021}
}
@article{M.Kim2004,
author = {Cortese, Giuliana and Gerds, Thomas A and Andersen, Per K},
doi = {10.1002/sim.5773},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Cortese2013.pdf:pdf},
journal = {Statistics in Medicine},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {18},
pages = {3089--3101},
title = {{Comparing predictions among competing risks models with time-dependent covariates}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3624763/pdf/nihms412728.pdf},
volume = {32},
year = {2013}
}
@article{Austin2017,
abstract = {Predicting outcomes that occur over time is important in clinical, population health, and health services research. We compared changes in different measures of performance when a novel risk factor or marker was added to an existing Cox proportional hazards regression model. We performed Monte Carlo simulations for common measures of performance: concordance indices (c, including various extensions to survival outcomes), Royston's D index, R2-type measures, and Chambless' adaptation of the integrated discrimination improvement to survival outcomes. We found that the increase in performance due to the inclusion of a risk factor tended to decrease as the performance of the reference model increased. Moreover, the increase in performance increased as the hazard ratio or the prevalence of a binary risk factor increased. Finally, for the concordance indices and R2-type measures, the absolute increase in predictive accuracy due to the inclusion of a risk factor was greater when the observed event rate was highe...},
author = {Austin, Peter C. and Pencinca, Michael J. and Steyerberg, Ewout W.},
doi = {10.1177/0962280214567141},
file = {:C\:/Users/mbrxsap3/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Austin, Pencinca, Steyerberg - 2017 - Predictive accuracy of novel risk factors and markers A simulation study of the sensitivity of dif.pdf:pdf},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Cox proportional hazards model,Monte Carlo simulations,Survival analysis,discrimination,model performance,predictive accuracy,predictive models,risk factors},
number = {3},
pages = {1053--1077},
pmid = {25656552},
title = {{Predictive accuracy of novel risk factors and markers: A simulation study of the sensitivity of different performance measures for the Cox proportional hazards regression model}},
volume = {26},
year = {2017}
}
@article{Royston2002,
abstract = {Modelling of censored survival data is almost always done by Cox proportional-hazards regression. However, use of parametric models for such data may have some advantages. For example, non-proportional hazards, a potential difficulty with Cox models, may sometimes be handled in a simple way, and visualization of the hazard function is much easier. Extensions of the Weibull and log-logistic models are proposed in which natural cubic splines are used to smooth the baseline log cumulative hazard and log cumulative odds of failure functions. Further extensions to allow non-proportional effects of some or all of the covariates are introduced. A hypothesis test of the appropriateness of the scale chosen for covariate effects (such as of treatment) is proposed. The new models are applied to two data sets in cancer. The results throw interesting light on the behaviour of both the hazard function and the hazard ratio over time. The tools described here may be a step towards providing greater insight into the natural history of the disease and into possible underlying causes of clinical events. We illustrate these aspects by using the two examples in cancer. Copyright {\textcopyright} 2002 John Wiley & Sons, Ltd.},
author = {Royston, Patrick and Parmar, Mahesh K.B.},
doi = {10.1002/sim.1203},
file = {:/nask.man.ac.uk/home$/Documents/JournalsandPapers/Royston2002.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Parametric models,Proportional hazards,Proportional odds,Splines,Survival analysis},
number = {15},
pages = {2175--2197},
pmid = {12210632},
title = {{Flexible parametric proportional-hazards and proportional-odds models for censored survival data, with application to prognostic modelling and estimation of treatment effects}},
volume = {21},
year = {2002}
}
